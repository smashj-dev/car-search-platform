name = "car-search-api"
main = "src/index.ts"
compatibility_date = "2024-12-01"
compatibility_flags = ["nodejs_compat"]

# D1 Database for structured car data
[[d1_databases]]
binding = "DB"
database_name = "car-search-db"
database_id = "a5d6b92b-397b-49a7-a951-466faecd9445"

# KV Namespace for hot cache (popular searches, recent queries)
[[kv_namespaces]]
binding = "CACHE"
id = "e9ea7aba70fb4d37a0f3b9de31c865ad"

# KV Namespace for user sessions
[[kv_namespaces]]
binding = "SESSIONS"
id = "cd3b9cbeb5b34a0fbb954dda70f52f04"

# R2 Bucket for raw scrape data storage (commented out until R2 is enabled)
# [[r2_buckets]]
# binding = "STORAGE"
# bucket_name = "kemi-scrapes"

# AI binding for Cloudflare Workers AI
[ai]
binding = "AI"

# Browser Rendering for scraping
browser = { binding = "BROWSER" }

# Environment variables (secrets added via wrangler secret put)
[vars]
ENVIRONMENT = "development"

# Queue for background scraping jobs (commented out - will be created manually)
# [[queues.producers]]
# binding = "SCRAPE_QUEUE"
# queue = "kemi-scrape-queue"

# [[queues.consumers]]
# queue = "kemi-scrape-queue"
# max_batch_size = 10
# max_batch_timeout = 30
# max_retries = 3
# dead_letter_queue = "kemi-scrape-dlq"

# Scheduled worker for automated scraping (every 4 hours) - disabled until queues are set up
# [triggers]
# crons = ["0 */4 * * *"]

# Email routing for notifications
# [send_email]
# Configured via Cloudflare dashboard for MailChannels integration
